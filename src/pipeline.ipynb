{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb07759",
   "metadata": {},
   "source": [
    "# 1 Load dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54d706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GithubRepositories\\RAG-system\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader \n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_file(path):\n",
    "    if path.endswith('.pdf'): # PDF file\n",
    "        pdf_loader = PyPDFLoader(path)\n",
    "        pdf_docs = pdf_loader.load()\n",
    "        return pdf_docs\n",
    "    \n",
    "    elif path.endswith('.docx'): # DOCX file\n",
    "        docx_loader = Docx2txtLoader(path)\n",
    "        docx_docs = docx_loader.load()\n",
    "        return docx_docs\n",
    "    \n",
    "    elif path.endswith('.txt'): # TXT file\n",
    "        text_loader = TextLoader(path, encoding='utf8')\n",
    "        text_docs = text_loader.load()\n",
    "        return text_docs\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2443b3",
   "metadata": {},
   "source": [
    "# 2 Tạo db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4812fa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# 1 Load documents\n",
    "docs = load_file(r\"D:\\GithubRepositories\\RAG-system\\docs\\doc.txt\")\n",
    "\n",
    "# 2 Split documents into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3 Create embeddings and store in vector database\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={'device': device})\n",
    "db = FAISS.from_documents(chunks, embeddings)\n",
    "db.save_local(\"../db/faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3418a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  887\n",
      "New documents added to the vector database.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs = load_file(r\"D:\\GithubRepositories\\RAG-system\\docs\\Giai_thuat_va_Lap_trinh.pdf\")\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(\"Number of chunks: \", len(chunks))\n",
    "db = FAISS.load_local(\"../db/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "db.add_documents(chunks)\n",
    "db.save_local(\"../db/faiss_index\")\n",
    "print(\"New documents added to the vector database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606726e4",
   "metadata": {},
   "source": [
    "# Khởi tạo RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d4066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "db = FAISS.load_local(\"../db/faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "model = GoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"\n",
    "        Hãy sử dụng đúng ngữ cảnh được cung cấp để trả lời câu hỏi.\n",
    "        Nếu không tìm thấy câu trả lời trong ngữ cảnh, hãy nói \"Thông tin này không có trong tài liệu được cung cấp.\".\n",
    "        Trả lời ngắn gọn tối đa ba câu. \n",
    "        Ngữ cảnh: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d80e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thông tin này không có trong tài liệu được cung cấp.\n",
      "Source:  D:\\GithubRepositories\\RAG-system\\docs\\Giai_thuat_va_Lap_trinh.pdf Page:  124\n",
      "Source:  D:\\GithubRepositories\\RAG-system\\docs\\Giai_thuat_va_Lap_trinh.pdf Page:  132\n",
      "Source:  D:\\GithubRepositories\\RAG-system\\docs\\Giai_thuat_va_Lap_trinh.pdf Page:  124\n"
     ]
    }
   ],
   "source": [
    "query = \"Merge sort là gì?\"\n",
    "result = chain.invoke({\"input\": query}) \n",
    "# Hàm invoke sẽ trả ra dict {\"input\": query, \"answer\": \"...\", \"context\": [...]}. \n",
    "# Trong đó, context là list các đoạn văn bản được trích dẫn từ tài liệu, answer là câu trả lời của model.\n",
    "print(result[\"answer\"])\n",
    "\n",
    "# Trích dẫn từ tài liệu nào\n",
    "for d in result[\"context\"]:\n",
    "    print(\"Source: \", d.metadata[\"source\"], \"Page: \", d.metadata[\"page\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4afc0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "docs = load_file(r\"D:\\GithubRepositories\\RAG-system\\docs\\Giai_thuat_va_Lap_trinh.pdf\")\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "chunks = splitter.split_documents(docs)\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "bm25_retriever.k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8c44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf(docs_list, k=60):\n",
    "    scores = {}\n",
    "    for docs in docs_list:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_id = doc.metadata.get(\"id\")\n",
    "            if doc_id not in scores:\n",
    "                scores[doc_id] = 0\n",
    "            scores[doc_id] += 1 / (k + rank + 1)\n",
    "    # Sort theo điểm RRF giảm dần\n",
    "    sorted_ids = sorted(scores, key=scores.get, reverse=True)\n",
    "    # Return tài liệu theo đúng thứ tự RRF\n",
    "    id_to_doc = {doc.metadata[\"id\"]: doc for docs in docs_list for doc in docs}\n",
    "    return [id_to_doc[i] for i in sorted_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bd687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retrieve(query):\n",
    "    bm25_docs = bm25_retriever.get_relevant_documents(query)\n",
    "    vector_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "    docs_rrf = rrf([bm25_docs, vector_docs])\n",
    "    return docs_rrf[:5]  # lấy top 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
